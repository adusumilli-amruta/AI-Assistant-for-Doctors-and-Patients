{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "id": "i7qb3dcPR22r",
        "outputId": "e298293c-6b85-4425-9fed-5cb67e85d4c8"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'streamlit'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-2dbde84de84a>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# app.py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mstreamlit\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerativeai\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgenai\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'streamlit'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "# app.py\n",
        "import streamlit as st\n",
        "from PIL import Image\n",
        "import google.generativeai as genai\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv()\n",
        "\n",
        "# Configure Gemini Pro\n",
        "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
        "model = genai.GenerativeModel('gemini-pro')\n",
        "\n",
        "# Set page configuration\n",
        "st.set_page_config(\n",
        "    page_title=\"Doc-Patient AI Assistant\",\n",
        "    page_icon=\"üë®‚Äç‚öïÔ∏è\",\n",
        "    layout=\"centered\"\n",
        ")\n",
        "\n",
        "# Add custom CSS\n",
        "st.markdown(\"\"\"\n",
        "<style>\n",
        ".stApp {\n",
        "    max-width: 800px;\n",
        "    margin: 0 auto;\n",
        "}\n",
        ".stTextArea {\n",
        "    min-height: 100px;\n",
        "}\n",
        "</style>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "# Initialize chat\n",
        "if \"chat\" not in st.session_state:\n",
        "    st.session_state.chat = model.start_chat(history=[])\n",
        "\n",
        "# Title and description\n",
        "st.title(\"üë®‚Äç‚öïÔ∏è Medical AI Assistant\")\n",
        "st.markdown(\"#### Your AI Medical Consultation Partner\")\n",
        "\n",
        "# Role selection\n",
        "role = st.radio(\n",
        "    \"Choose your role:\",\n",
        "    [\"üë®‚Äç‚öïÔ∏è Doctor\", \"üè• Patient\"],\n",
        "    horizontal=True\n",
        ")\n",
        "\n",
        "# Input area\n",
        "user_input = st.text_area(\n",
        "    \"Describe your medical concern or enter your query:\",\n",
        "    height=100\n",
        ")\n",
        "\n",
        "# Define prompts\n",
        "DOCTOR_PROMPT = \"\"\"You are an AI medical assistant helping a doctor.\n",
        "Consider:\n",
        "1. Differential diagnoses\n",
        "2. Recommended tests\n",
        "3. Treatment options\n",
        "4. Recent medical research\n",
        "5. Professional medical terminology\n",
        "\n",
        "Query: {query}\n",
        "\"\"\"\n",
        "\n",
        "PATIENT_PROMPT = \"\"\"You are an AI medical assistant helping a patient.\n",
        "Consider:\n",
        "1. General symptoms assessment\n",
        "2. Basic health advice\n",
        "3. Whether to seek immediate medical attention\n",
        "4. Preventive measures\n",
        "5. Simple, clear explanations\n",
        "\n",
        "Query: {query}\n",
        "\"\"\"\n",
        "\n",
        "# Generate response\n",
        "if st.button(\"Get AI Consultation\", type=\"primary\"):\n",
        "    if user_input:\n",
        "        with st.spinner(\"Generating response...\"):\n",
        "            # Select prompt based on role\n",
        "            prompt = DOCTOR_PROMPT if \"Doctor\" in role else PATIENT_PROMPT\n",
        "            formatted_prompt = prompt.format(query=user_input)\n",
        "\n",
        "            try:\n",
        "                # Get response from Gemini\n",
        "                response = st.session_state.chat.send_message(formatted_prompt)\n",
        "\n",
        "                # Display response in a nice format\n",
        "                st.markdown(\"### ü§ñ AI Assistant Response:\")\n",
        "                st.markdown(response.text)\n",
        "\n",
        "                # Add disclaimer\n",
        "                st.markdown(\"\"\"\n",
        "                ---\n",
        "                *Disclaimer: This AI assistant provides general information and\n",
        "                should not replace professional medical advice. Always consult\n",
        "                with a qualified healthcare provider for medical decisions.*\n",
        "                \"\"\")\n",
        "\n",
        "            except Exception as e:\n",
        "                st.error(f\"An error occurred: {str(e)}\")\n",
        "    else:\n",
        "        st.warning(\"Please enter your query first.\")\n",
        "\n",
        "# Chat history\n",
        "if st.checkbox(\"Show Chat History\"):\n",
        "    st.markdown(\"### üìù Chat History\")\n",
        "    for message in st.session_state.chat.history:\n",
        "        role = \"üë§ User\" if message.role == \"user\" else \"ü§ñ Assistant\"\n",
        "        st.markdown(f\"**{role}:**\")\n",
        "        st.markdown(message.parts[0].text)\n",
        "        st.markdown(\"---\")\n",
        "\n",
        "# Footer\n",
        "st.markdown(\"\"\"\n",
        "---\n",
        "Made with ‚ù§Ô∏è using Streamlit and Google's Gemini Pro\n",
        "\"\"\")"
      ]
    }
  ]
}